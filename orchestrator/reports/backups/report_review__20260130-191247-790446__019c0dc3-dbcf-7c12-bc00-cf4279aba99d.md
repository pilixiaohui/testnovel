已阅读审阅行为规范
iteration: 16
review_mode: single

## 任务理解

审阅的任务：调查 `project/scripts/ten_chapter_novel_e2e.py`（M4-T3）执行 60s 超时的根本原因  
验收标准：明确超时根因（配置问题/LLM调用/脚本逻辑）+ 提出修复建议（必要时给出脚本修改方案）

## 验收执行

- 诊断命令: `ss -ltnp | grep ':8000' || true`
- 返回码: 0
- 结果摘要: 8000 端口 LISTEN（后端进程在跑）

- 诊断命令: `curl -s -o /dev/null -w '%{http_code}\n' http://localhost:8000/ || true`
- 返回码: 0
- 结果摘要: `404`（服务存活，根路由不存在属正常）

- 诊断命令: `rg -n '^SNOWFLAKE_ENGINE' project/backend/.env || true`
- 返回码: 0
- 结果摘要: `SNOWFLAKE_ENGINE=gemini`

- 诊断命令: `rg -n '^TOPONE_TIMEOUT_SECONDS' project/backend/.env || true`
- 返回码: 0
- 结果摘要: `TOPONE_TIMEOUT_SECONDS=120`

- 覆盖率: 不适用（本工单为超时根因调查，无 pytest 覆盖率要求）

## 代码深度审查

### 实现代码审查
- 审查文件: `project/scripts/ten_chapter_novel_e2e.py`
- 审查文件: `project/backend/app/main.py`
- 审查文件: `project/backend/app/services/topone_client.py`
- 审查内容:
  | 检查项 | 结果 | 说明 |
  |-------|------|------|
  | 超时配置一致性 | 不符合 | 脚本 `API_TIMEOUT=60`，而后端 TopOne 调用超时为 `120s`，脚本会先于后端超时导致误判“服务不可达” |
  | 是否调用真实 LLM | 是 | `.env` 中 `SNOWFLAKE_ENGINE=gemini`，Step1-6 走 `ToponeGateway`；章节 render 端点固定依赖 `get_topone_gateway()` |
  | 是否存在死循环/阻塞等待 | 未发现显式死循环 | 主要风险来自“单请求内多次 LLM 调用累加耗时”（step5b）与“10 次章节渲染”（render） |
  | 错误处理完整性 | 基本完整 | 后端将 TopOne 异常转为 400；但“慢/等待”不会触发快速失败，最终由客户端超时体现 |
  | 边界条件处理 | 已考虑部分 | step5b 强制章节总数=10；render 强制字数 1800-2200（不含标点空白） |

- 代码片段证据:
```python
# project/scripts/ten_chapter_novel_e2e.py:18-31
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000/api/v1").rstrip("/")
TIMEOUT = float(os.getenv("API_TIMEOUT", "60"))

def _post(path: str, payload: Dict[str, Any]) -> Any:
    url = f"{API_BASE_URL}{path}"
    response = requests.post(url, json=payload, timeout=TIMEOUT)
```

```dotenv
# project/backend/.env:6
TOPONE_TIMEOUT_SECONDS=120
# project/backend/.env:15
SNOWFLAKE_ENGINE=gemini
```

```python
# project/backend/app/main.py:135-144
def get_llm_engine() -> LLMEngine | LocalStoryEngine | ToponeGateway:
    engine_mode = _require_snowflake_engine_mode()
    if engine_mode == "local":
        return LocalStoryEngine()
    if engine_mode == "llm":
        return LLMEngine()
    if engine_mode == "gemini":
        return get_topone_gateway()
```

```python
# project/backend/app/main.py:312-323
planned: list[tuple[str, list[dict[str, Any]]]] = []
total_count = 0
for act in acts:
    ...
    generated = await engine.generate_chapter_list(payload.root, act, payload.characters)
    ...
    total_count += len(generated)
    planned.append((act_id, generated))
if total_count != 10:
    raise HTTPException(status_code=400, detail="chapter count must be exactly 10")
```

```python
# project/backend/app/main.py:601-626
@app.post("/api/v1/chapters/{chapter_id}/render")
async def render_chapter_endpoint(
    chapter_id: str,
    gateway: ToponeGateway = Depends(get_topone_gateway),
    storage: GraphStoragePort = Depends(get_graph_storage),
) -> dict[str, str]:
    ...
    content = await gateway.render_scene(payload)
```

```python
# project/backend/app/services/topone_client.py:100-110
async with httpx.AsyncClient(
    base_url=self.base_url,
    timeout=timeout or self.timeout_seconds,
    transport=transport,
) as client:
    response = await client.post(...)
```

- 实现审查结论: 根因明确为“超时配置不一致 + 真实 LLM 调用耗时不可控/累加”，最可疑卡点为 `step5b`（单请求内多次 LLM 调用）与章节 `render`（10 次重调用）。

### 测试代码审查
- 测试文件: 存在：`project/backend/tests/integration/test_ten_chapter_e2e.py`
- 对比结论:
  - 集成测试通过 `dependency_overrides` 注入 `FakeEngine/FakeGateway`，不触发真实 TopOne/外部网络，因此**无法代表** M4-T3 脚本（真实服务 + 真实 LLM）的耗时与超时行为。
- 测试覆盖情况:
  | 功能点 | 是否有测试 | 测试是否正确 |
  |-------|-----------|-------------|
  | Step1-6 基本流程 | 是 | 是（但为 fake 引擎） |
  | 章节 render 字数范围 | 是 | 部分（fake gateway 返回固定 2000 字符串；不覆盖真实 LLM 慢/超时场景） |
  | “脚本级超时/慢请求”场景 | 否 | 不适用（当前测试策略刻意避开外部 LLM） |
- 代码片段证据:
```python
# project/backend/tests/integration/test_ten_chapter_e2e.py:115-133
monkeypatch.setenv("SNOWFLAKE_ENGINE", "local")
...
app.dependency_overrides[main.get_llm_engine] = lambda: engine
...
app.dependency_overrides[main.get_topone_gateway] = lambda: FakeGateway()
```
- 测试质量结论: 符合“稳定可重复”的集成测试目标，但与 M4-T3（真实 LLM + 脚本 60s timeout）不一致，无法覆盖本次超时问题。

## 结论

结论：PASS  
阻塞：无

## 建议

1. 先修“超时策略不一致”（最小改动、最可能立刻解决）  
   - 运行脚本时设置 `API_TIMEOUT` ≥ 后端可能的单请求最长耗时（至少 >120s；若 step5b 触发多次 LLM 调用，建议显著高于 120s）。  
2. 更符合“快速失败”的方向（需要 DEV 做取舍）  
   - 收紧后端 `TOPONE_TIMEOUT_SECONDS`（例如 ≤60），并将脚本 `API_TIMEOUT` 设置略高于后端（例如 70-90），避免后端长时间挂起导致脚本误判。  
3. 精确定位“当次 DEV 超时卡点”（建议 MAIN 要求 DEV 补充证据）  
   - 重跑脚本并记录最后一个 `print()` 阶段；脚本每步都有明确日志（Step4/5a/5b/6/Render），可直接确认超时发生在 `step5b` 还是 `render`。  
4. 可选的结构性改进（后续里程碑再做）  
   - `render` 端点目前固定依赖 `get_topone_gateway()`（与 `SNOWFLAKE_ENGINE` 无关），导致“本地/Mock”模式下也绕不开真实 LLM；若需要可重复的脚本验收，建议提供可切换的 renderer/gateway 注入策略（保持 fail-fast，不做兜底）。

【MCP调用简报】
服务: 本地 shell（functions.shell_command）  
触发: 调查脚本超时根因，需要验证服务存活、引擎模式与超时配置，并对照端点实现/测试替身策略  
参数: `ss/curl/rg` + 关键文件行号审阅（`ten_chapter_novel_e2e.py`、`main.py`、`topone_client.py`、`test_ten_chapter_e2e.py`、`conftest.py`）  
结果: 确认 `API_TIMEOUT=60` 与后端 `TOPONE_TIMEOUT_SECONDS=120` 冲突；step5b 多次 LLM 调用与章节 render 重调用是最可能超时点；集成测试使用 fake 不覆盖脚本慢/超时行为  
状态: 成功