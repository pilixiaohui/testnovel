# **基于 Python Native 与 Gemini 3 的全链路长篇小说智能创作系统架构设计 (V3.0)**

**文档版本**: 3.1 (图数据库重构版)
**最后更新**: 2026-01-18
**重要变更**: 图数据库从 Kùzu 升级至 Memgraph，补全 72% 核心功能

## **0. Phase 1 范围声明（本迭代）**

- **仅后端范围**：聚焦 Snowflake 流程编排与 Memgraph 图存储的后端能力，交付 REST API。
- **不在本迭代范围**：前端交互（React Flow / Tiptap）、LanceDB、LangGraph。
- **重构说明**：本版本采用 Memgraph 替代 Kùzu，实现高并发、时序记忆、完整版本控制等核心功能。详见 `doc/graph_refactor_final_plan.md`。

## **1. 绪论：结构主义与涌现论的统一**

### **1.1 核心定义：分形叙事对象（The Fractal Narrative Object）**

本系统将长篇小说定义为一个\*\*自顶向下生长（Top-Down Growth）**与**自底向上涌现（Bottom-Up Emergence）\*\*相结合的复杂系统。

  * **宏观（Structure）**：采用**雪花写作法**作为系统的“编译预处理”阶段。小说不再是线性的文本流，而是一个由\*\*“核心概念 -\> 人物原型 -\> 剧情骨架 -\> 场景节点”\*\*逐级展开的分形树状结构。
  * **微观（Negotiation）**：在具体的“场景节点”内，采用\*\*“人机协商机制”\*\*。每一个场景的生成，都是一次对宏观设定的实例化与微调。
  * **动态性（Causality）**：利用 **Kùzu 图数据库** 维护叙事真值。宏观结构的改变（如修改大纲）会触发全图的**一致性检查（Consistency Check）**；微观剧情的突变（如主角意外死亡）会触发对后续未写章节的**多米诺重构（Ripple Refactoring）**。

### **1.2 解决的核心矛盾**

1.  **“写得长”与“记得住”的矛盾**：通过**雪花层级索引**解决。AI 不需要每次都读全文，只需读取当前层级的结构数据（大纲）+ 当前场景的动态状态（图谱）。
2.  **“计划性”与“意外感”的矛盾**：雪花提供计划，协商机制提供意外。系统允许在微观层面偏离计划，并自动计算偏离后的逻辑代价与局部修复方案。

-----

## **2. 系统总体架构设计**

采用 **Layered Event-Driven Architecture（分层事件驱动架构）**。系统分为**结构层（The Architect）**、**逻辑层（The Simulator）**、**渲染层（The Renderer）与数据层（The Ontology）**。

### **2.1 技术栈选型（工业级全景）**

| 组件层级 | 选型技术 | 核心选型原理与深度落地策略 |
| :--- | :--- | :--- |
| **开发语言** | **Python 3.11+** | 利用最新版 Python 的 `TaskGroup` 优化异步并发，结合 `Pydantic V2` 的 Rust 内核提供毫秒级的数据校验能力。 |
| **Web 框架** | **FastAPI + Rust Core** | 承载高频的 WebSocket 交互（“协商面板”）。利用 `BackgroundTasks` 处理耗时的全书一致性扫描与惰性计算。 |
| **结构化引擎** | **Instructor / Marvin** | **[新增]** 专门用于强制 LLM 输出结构化 JSON。在“雪花法”生成大纲阶段，确保输出严格符合 Pydantic 定义的层级结构。 |
| **智能体编排** | **LangGraph** | 构建**嵌套状态机**。外层循环负责“章节推进”，内层循环负责“单场景的逻辑协商、人工确认与渲染”。 |
| **宏观规划模型** | **Gemini 3 Pro (Architect)** | **大局观**。负责执行雪花法的前 4 步（一句话 -\> 一段话 -\> 人物小传 -\> 扩写大纲）。利用其超长 Context 保持全书结构。 |
| **微观推理模型** | **Gemini 3 Pro (Reasoning)** | **逻辑检察官**。在单场景生成前，结合 Kùzu 图谱进行反事实推理，检测逻辑漏洞；支持记录“逻辑例外（Logic Exception）”标记。 |
| **文学渲染模型** | **Gemini 3 Pro (Creative)** | **金牌写手**。负责具体的文本生成，专注于修辞、感官描写与情感渲染。 |
| **状态提取模型** | **gemini-3-flash-preview** | **书记员**。文本定稿后的后台处理，低成本提取实体状态变更，生成“状态变更预案”供人工审核。 |
| **图数据库** | **Memgraph** | **叙事关系引擎**。存储人物关系网（雪花法第5步）及动态剧情状态。支持高并发 ACID 事务、时序边机制、快照查询，进行复杂的多跳逻辑检索。 |
| **图数据库 ORM** | **GQLAlchemy** | **类型安全的图查询层**。提供 Pydantic 风格的节点/边模型定义，防止 SQL 注入，简化 Cypher 查询构建。 |
| **向量数据库** | **LanceDB** | **风格与规则库**。存储世界观设定集（Bible）、历史精彩片段（用于 Few-shot 学习）及用户偏好的文风切片。 |
| **前端交互** | **React Flow + Tiptap** | **[新增]** 使用 React Flow 可视化展示“雪花结构树”，Tiptap 作为富文本编辑器；集成“状态确认面板”与“强制执行”控件。 |

-----

## **3. 数据层架构：雪花分形本体 (The Snowflake Ontology)**

数据层必须能够承载雪花写作法的层级结构，并将其映射为图谱中的节点。

### **3.0 图数据库重构说明**

**重构背景**：原 Kùzu 嵌入式方案存在以下限制：
- 单连接架构，无法支持多用户并发
- 缺失动态状态追踪（无时序边机制）
- 缺失一致性检查（无法查询历史状态）
- 缺失自动影响分析（无依赖矩阵优化）
- 功能完整性仅 28%，无法满足 V3.0 设计目标

**重构方案**：升级至 Memgraph + GQLAlchemy
- **并发能力**：支持 100+ 并发用户，ACID 事务保证
- **时序记忆**：时序边（start_scene_seq/end_scene_seq）+ 快照机制
- **性能优化**：查询性能提升 20-200 倍（快照命中），影响分析提升 100 倍（依赖矩阵）
- **版本控制**：完整的 Git 式分支管理（Branch/Commit/Merge）
- **云端集成**：Gemini Flash API 实体消解，成本降低 67%，无需本地 GPU

**迁移策略**：
1. 保留 Kùzu 数据作为备份
2. 提供完整的数据迁移脚本（导出 → 转换 → 导入）
3. 提供回滚方案（可随时切换回 Kùzu）
4. 预计 11 周完整交付（详见 `doc/graph_refactor_final_plan.md`）

### **3.1 宏观结构模型 (Structure Models)**

  * **SnowflakeRoot (雪花根节点)**:
      * `logline`: str (一句话核心，如“一个黑客发现了矩阵的真相”)
      * `three_disasters`: List[str] (三个主要冲突点，雪花法第2步)
      * `ending`: str (结局)
      * `theme`: str (核心主旨)
  * **CharacterSheet (人物小传 - 雪花第3步)**:
      * `entity_id`: UUID (关联到 Kùzu 的 Entity 节点)
      * `ambition`: str (具体目标：想要什么)
      * `conflict`: str (阻碍：为什么得不到)
      * `epiphany`: str (顿悟：如何改变)
      * `voice_dna`: str (语言风格指纹)
  * **SceneNode (场景节点 - 雪花第6步)**:
      * `id`: UUID
      * `parent_act_id`: UUID (所属幕/章节)
      * `pov_character_id`: UUID (视点人物)
      * `expected_outcome`: str (大纲计划的结果)
      * `actual_outcome`: str (生成后的实际结果 - 允许偏差)
      * `conflict_type`: str (如 "Man vs Self", "Man vs Nature")
      * **[新增]** `logic_exception`: bool (是否包含强制执行的非逻辑剧情)

### **3.2 通用实体与状态模型 (Entity & State Models)**

  * **UniversalEntity (通用实体)**:
      * `id`, `name`, `tags`
      * `entity_type`: str (Character, Location, Item)
      * `semantic_states`: Dict[str, str] (如 `{"mental": "Despair", "location": "Sector 7"}`)
      * `arc_status`: str (对应 CharacterSheet 的进度，如 "Refusal of the Call")
  * **TemporalRelation (时序关系边)**:
      * `relation_type`: str (关系类型，如 HATES, LOVES, AT, HAS)
      * `tension`: int (叙事张力值，0-100)
      * **`start_scene_seq`**: int (生效场景序号，支持时间旅行查询)
      * **`end_scene_seq`**: Optional[int] (失效场景序号，NULL 表示当前有效)
      * **`branch_id`**: str (分支标识，支持多分支并行)
      * 雪花法第 5 步的人物关系网直接转化为图谱中的时序边。
  * **WorldSnapshot (世界状态快照)**:
      * `id`: UUID
      * `scene_version_id`: UUID (关联场景版本)
      * `branch_id`: str (分支标识)
      * `scene_seq`: int (场景序号)
      * `entity_states`: Dict (JSON 序列化的完整世界状态)
      * 每 10 个场景自动创建快照，优化历史状态查询性能。

### **3.3 数据库映射策略**

  * **Memgraph 双子图架构 (Dual Subgraph)**:
      * **结构子图 (Structure Subgraph)**: 管理写作过程的版本控制
          * Nodes: `Root`, `Branch`, `BranchHead`, `Commit`, `SceneOrigin`, `SceneVersion`
          * Edges: `HEAD`, `PARENT`, `INCLUDES`, `OF_ORIGIN`
      * **叙事子图 (Narrative Subgraph)**: 管理故事世界观的动态演变
          * Nodes: `Entity`, `WorldSnapshot`
          * Edges: `TemporalRelation` (带 start_scene_seq/end_scene_seq 的时序边)
      * **桥接关系**: `[:ESTABLISHES_STATE]` 连接 SceneVersion 和 WorldSnapshot
  * **核心优化机制**:
      * **时序边失效机制**: 状态变更时自动失效旧边，创建新边，保留完整历史
      * **快照+增量混合**: 每 10 个场景创建快照，查询时从最近快照恢复 + 回放增量变更
      * **依赖矩阵优化**: 预计算场景-实体依赖矩阵，影响分析从 O(S×E) 降至 O(E)
      * **实体消解**: 使用 Gemini Flash 进行云端实体识别和代词消解，无需本地 GPU

-----

## **4. 核心算法流程：从宏观规划到微观渲染**

### **阶段一：结构化生长 (The Snowflake Process)**

*此阶段由 Gemini 3 Pro (Architect) 主导，用户处于“上帝视角”。*

1.  **Step 1 - Logline**: 用户输入模糊想法，AI 提炼为 10 个版本的“一句话故事”，用户选择其一。
2.  **Step 2 - Expansion**: AI 将 Logline 扩充为“三幕五节点”结构（开端、灾难1、灾难2、灾难3、结局）。
3.  **Step 3 - Character Definition**: 系统为每个主要角色生成 `CharacterSheet`。**关键点**：AI 会自动检查角色动机与主线剧情是否冲突（例如：主线要探险，主角动机却是想宅在家）。
4.  **Step 4 - Scene List Generation**: AI 根据扩充后的大纲，生成一份包含 50-100 个节点的 `SceneList`。
      * *数据动作*：这些场景被批量写入 Kùzu，形成初始的**叙事骨架图**。

### **阶段二：场景级协商与渲染 (The Negotiation Loop)**

*此阶段进入具体的章节创作，用户处于“导演视角”。*

#### **Step 1: 场景上下文加载 (Context Loading)**

当用户点击"生成第 5 场"时，Python 后端执行：

1.  **结构检索**：从 Memgraph 读取该场景的 `expected_outcome`（来自雪花大纲）。
2.  **状态检索**：通过时序边查询，读取当前所有在场 `Entity` 在指定场景序号的 `semantic_states`。
      * 优化策略：优先查询最近的 WorldSnapshot 快照（每 10 场景一个），然后回放增量变更。
      * 查询复杂度：从 O(S×E) 优化至 O(E×5) 平均，快照命中时为 O(1)。
3.  **前情摘要**：从 LanceDB 检索上一场结尾的摘要。

#### **Step 2: 意图协商与逻辑推演 (Simulated Negotiation)**

*这是本方案的灵魂，加入了强制执行机制。*

1.  **用户输入**：用户可以接受大纲的安排，也可以输入新的指令（“这一场让主角提前遇到反派”）。
2.  **逻辑检察官 (Gemini 3 Pro Reasoning)**：
      * 输入：`[当前状态] + [大纲要求] + [用户指令]`
      * **推理任务**：
          * 一致性检查：反派现在哪里？（查询图谱：反派在千里之外）。
          * 雪花结构影响：如果提前相遇，后续的“灾难2”是否失效？
      * **输出报告**：
        > "⚠️ **结构性警告**：根据大纲，主角应在第 15 场才遇见反派。如果现在相遇，会导致第 10-14 场的铺垫作废。
        > **建议 A**：保持大纲，安排反派的‘投影’或‘信使’出现。
        > **建议 B**：修改大纲，触发‘逻辑影响分析’。"

#### **Step 3: 共识、强制执行与渲染 (Consensus, Force & Rendering)**

1.  **决策路径**：
      * **路径 A**：用户采纳 AI 建议，系统按逻辑最优解生成。
      * **路径 B（强制执行）**：用户点击\*\*“强制执行（Force Execute）”\*\*按钮。用户批注：“我知道不合理，但为了戏剧性冲突必须如此。”
          * 系统动作：忽略逻辑警告，将当前场景标记为 `Logic Exception`，并记录用户的强制理由，防止逻辑检察官在后续步骤中反复报错。
2.  **文学渲染 (Gemini 3 Pro Creative)**：
      * Prompt 策略：注入 `CharacterSheet.voice_dna` 和 `SceneNode.conflict_type`。若存在强制标记，增加 Prompt 权重：“优先满足戏剧性指令，弱化物理逻辑约束”。
      * 生成正文。

#### **Step 4: 状态提取与人工确认 (Extraction & HITL Verification)**

*引入 Human-in-the-loop 机制，防止错误状态污染数据库。*

1.  **gemini-3-flash-preview** 分析生成的文本，提取潜在的实体状态变更（如 `HP: 100% -> 10%`, `Location: Safehouse -> Unknown`）。
      * 使用云端 Gemini Flash API (Topone API)，成本降低 67%，速度提升 1.5 倍。
      * 支持实体消解：自动识别代词指代（"他" -> "John"），重复实体检测准确率 > 95%。
2.  **人工确认/修正面板 (The Confirmation Panel)**：
      * 系统弹出一个非模态侧边栏，列出 AI 识别到的所有状态变更。
      * **展示形式**：Diff 视图（旧状态 vs 新状态）。
      * **用户动作**：用户快速浏览，勾选确认准确的变更，或手动修正错误的提取（如 AI 误将比喻句当成事实）。
3.  **微观更新**：仅将用户确认后的状态回写至 Memgraph 数据库。
      * 使用时序边失效机制：旧边设置 end_scene_seq，创建新边 start_scene_seq = 当前场景。
      * 事务保证原子性，支持并发写入（乐观锁机制）。
4.  **宏观更新**：将该场景标记为 `Completed`，并记录 `actual_outcome`。
      * 每 10 个场景自动创建 WorldSnapshot 快照，优化后续查询性能。

-----

## **5. 深度功能：懒惰计算与局部修复 (Lazy Evaluation & Local Repair)**

为了解决“多米诺重构”可能导致的计算资源爆炸和用户体验中断，本系统摒弃全量重构，采用**分级响应机制**来处理剧情偏差。

### **5.1 策略一：局部修复 (Local Patching)**

当 `actual_outcome` 与 `expected_outcome` 出现中度偏差（如：主角选择了一条不同的大纲路线，但目的地相同）时，系统启动**Architect Agent** 进行局部收敛计算：

  * **收敛窗口**：仅尝试修改**未来最近的 3 个节点**（N+1, N+2, N+3）。
  * **任务目标**：修改这 3 个场景的摘要，使得剧情在第 N+4 个场景回归原大纲的轨道。
  * **用户感知**：几乎无感，后台静默完成 Memgraph 节点的更新。
  * **影响分析优化**：使用依赖矩阵算法，预计算场景-实体依赖关系，查询复杂度从 O(S×E) 降至 O(E)。

### **5.2 策略二：脏标记机制 (Dirty Flags)**

当偏差过大（如：关键道具被销毁，导致结局无法发生），且无法在 3 个节点内收敛时，系统启用**惰性计算**：

  * **Dirty Marking**：系统分析受影响的逻辑链条，将远端的受影响场景节点（如第 40 场、第 50 场）在 React Flow 视图中标记为 **`DIRTY`（橙色状态）**。
  * **延迟重构**：此时系统**不**立即重写这些大纲。只有当用户真正点击进入或接近这些 `DIRTY` 节点时，才触发该局部的重构请求。
  * **优势**：避免了因为一个冲动的改动而重写半本书，节省大量 Token 和时间。
  * **影响分析算法**：
      * 首次构建依赖矩阵：O(S×E) 复杂度
      * 后续查询：O(E) 复杂度（矩阵向量乘法）
      * 在 100 场景规模下性能提升 100 倍

### **5.3 策略三：Git 式分支管理 (Branching)**

借鉴代码管理理念，解决"后悔药"问题：

  * **Master 分支**：始终保留原定的雪花大纲结构。
  * **Dev 分支**：当出现重大剧情偏离时，系统自动创建一个新的 `Dev` 变体分支。
  * **对比与合并**：用户可以在双视窗中对比 `Master` 和 `Dev` 的后续发展差异，手动选择 `Merge`（采纳新大纲）或 `Revert`（回滚剧情）。
  * **实现机制**：
      * Branch 节点：存储分支元数据（parent_branch_id, fork_scene_origin_id）
      * BranchHead 节点：使用乐观锁（version 字段）支持并发更新
      * 时序边隔离：每条边带 branch_id，支持多分支并行查询
      * 完整的版本控制：Commit 节点记录每次变更历史

-----

## **6. 交互层设计：双视窗工作台**

### **6.1 左视窗：分形结构树 (The Snowflake View)**

  * 使用 React Flow 展示。
  * 根节点是 Logline，展开是 Acts，再展开是 Scenes。
  * **状态颜色可视化**：
      * 🟢 已完成（Committed）
      * 🔵 进行中（Active）
      * ⚪ 待生成（Planned）
      * **🟣 逻辑例外（Exception）**：高亮显示强制执行的节点，提示此处存在逻辑断层。
      * **🟠 需修复（Dirty / Impacted）**：直观展示剧情偏离的波及范围，点击可查看修复建议。
  * 用户可以直接拖拽节点调整大纲顺序，后端自动同步更新 Kùzu 里的边。

### **6.2 右视窗：协商与编辑器 (The Negotiation Editor)**

  * **上方：导演控制台**。
      * 显示当前场景的“任务目标”（来自雪花大纲）。
      * 输入框：输入导演批注。
      * **逻辑推演面板**：
          * 展示 Gemini 的分析报告（通过/警告/局部修复方案）。
          * **[关键控件] 强制执行按钮**：允许忽略警告，强制按用户意图生成，并自动打上 `Logic Exception` 标签。
  * **下方：沉浸式编辑器**。
      * 流式显示生成的正文。
      * 支持手动修改。
      * **状态确认侧栏**：文本生成完毕后自动滑出，展示 AI 提取的 `Entity State Diff`，等待用户点击“确认同步”后才写入数据库。

-----

## **7. 实施路径与关键代码逻辑**

### **7.1 核心数据结构与健壮图更新 (Python 3.11 + Pydantic V2)**

为了支撑“惰性计算”、“局部修复”以及“人工介入验证”，需要更健壮的数据模型来量化逻辑影响。

```python
from enum import Enum
from typing import List, Optional, Dict
from pydantic import BaseModel, Field
from uuid import UUID, uuid4

class ImpactLevel(str, Enum):
    NEGLIGIBLE = "negligible"  # 细节变动，无需重构
    LOCAL = "local"            # 仅影响接下来的几章（可局部修复）
    CASCADING = "cascading"    # 蝴蝶效应，全书重构（需标记 Dirty）

class SceneNode(BaseModel):
    """雪花法第6步：场景节点"""
    id: UUID = Field(default_factory=uuid4)
    title: str
    expected_outcome: str
    is_dirty: bool = False  # 脏标记
    logic_exception: bool = False # 强制执行标记
    branch_id: str = "master" # 分支管理

class StateChangeProposal(BaseModel):
    """待人工确认的状态变更提案"""
    entity_id: UUID
    entity_name: str
    old_state: Dict[str, str]
    new_state: Dict[str, str]
    confidence: float

async def on_scene_complete(scene_id: UUID, content: str, user_interface_callback):
    """
    场景完成后的处理流程，包含 HITL 验证
    """
    # 1. 提取状态变更（使用 Gemini Flash 云端 API）
    extractor = GeminiFlashExtractor()
    changes: List[StateChangeProposal] = await extractor.extract(content)

    # 2. 调用前端回调，请求人工确认 (Human-in-the-loop)
    # 这一步会暂停流程，直到前端返回确认后的 verified_changes
    verified_changes = await user_interface_callback.request_verification(changes)

    # 3. 写入数据库 (仅写入人工确认过的数据)
    # 使用时序边失效机制：旧边设置 end_scene_seq，创建新边
    await memgraph_storage.batch_update_states_with_temporal_edges(verified_changes)

    # 4. 创建世界状态快照（每 10 个场景）
    if scene_id % 10 == 0:
        await memgraph_storage.create_world_snapshot(scene_id)

    # 5. 后台触发影响分析 (Fire and Forget)
    background_tasks.add_task(handle_ripple_effect, scene_id, content)

async def handle_ripple_effect(scene_id, content):
    # 如果节点被标记为 Logic Exception，则跳过常规逻辑检查，防止报错
    scene = await memgraph_storage.get_scene(scene_id)
    if scene.logic_exception:
        return

    # 使用依赖矩阵优化的影响分析算法
    result = await analyze_impact_with_dependency_matrix(...)
    if result.impact == ImpactLevel.LOCAL:
        await apply_local_patch(result.suggested_patch)
    elif result.impact == ImpactLevel.CASCADING:
        await mark_future_nodes_dirty(scene_id)
```

### **7.2 逻辑检察官 Prompt 设计 (System Prompt)**

```text
你是一个严苛的小说逻辑编辑。你的任务不是写作，而是检查用户意图是否破坏了世界观或故事结构。

输入数据：
1. [当前大纲要求]：主角在本场应该遭遇挫折。
2. [世界状态]：主角持有神器(ID:X)，HP: 100%（健康），当前位置：安全屋。
3. [用户意图]：让主角在这里被一个小混混打成重伤。
4. [指令模式]：Standard | ForceExecute

分析步骤：
1. 若指令模式为 ForceExecute：直接通过，但在 reasoning 中注明"剧情服务于戏剧性，物理逻辑被重写"。
2. 若指令模式为 Standard：
   - 检查能力值对比：主角持有神器且满状态，被小混混重伤是否合理？(逻辑性)
   - 检查大纲一致性：大纲要求遭遇挫折，"重伤"符合挫折定义，但执行方式可能不合理。

输出格式：JSON (LogicCheckResult)
```

### **7.3 落地路线图**

1.  **里程碑 1：图数据库重构 (Week 1-2)**
      * 搭建 Memgraph 环境，彻底删除旧 Kùzu 代码。
      * 定义 GQLAlchemy ORM 模型（双子图架构）。
      * 实现基础 CRUD 操作，完成性能 POC 验证。
2.  **里程碑 2：时序边与快照机制 (Week 3-5)**
      * 实现时序边失效逻辑（start_scene_seq/end_scene_seq）。
      * 实现 WorldSnapshot 快照机制（每 10 场景）。
      * 实现时间旅行查询优化（快照+增量混合）。
      * 开发 Git 式分支管理逻辑（Branch/BranchHead/Commit）。
3.  **里程碑 3：实体消解与影响分析 (Week 6-7)**
      * 集成 Gemini Flash API (Topone API) 进行实体消解。
      * 实现依赖矩阵优化的影响分析算法。
      * 实现 `Dirty` 状态传播与局部修复算法。
4.  **里程碑 4：雪花引擎与协商闭环 (Week 8-9)**
      * 实现 Logline 到 Scene List 的自动扩写算法。
      * 开发 Gemini 3 Pro 的逻辑推演 Prompt，实现 `ImpactLevel` 的判定与 `Logic Exception` 处理。
      * **重点开发**：前端"状态确认面板"与后端的状态变更 Diff 算法，打通 HITL 流程。
5.  **里程碑 5：性能优化与全量测试 (Week 10-11)**
      * 性能压测（100 QPS 混合读写，100 并发用户）。
      * 索引优化（时序边复合索引，快照查询优化）。
      * 进行 20 万字长篇生成的连贯性压力测试，重点测试强制执行后的逻辑自愈能力。
      * 完善 API 文档、部署文档、架构文档。

-----

## **8. 总结**

这个 V3.0 方案不仅仅是一个工具，它是一种**全新的创作工作流**。

  * 它尊重**经典叙事学（雪花法）**，保证小说有骨架，不会写散。
  * 它利用**前沿 AI（Gemini 3 + Memgraph）**，保证剧情有逻辑，不会崩坏。
  * 它通过**Human-in-the-loop（人工确认）与强制执行机制**，完美平衡了 AI 的自动化效率与人类作者的绝对控制权，解决了 AI 创作中的"幻觉污染"与"逻辑僵化"难题。

### **8.1 核心技术优势**

  * **高并发架构**：Memgraph 支持数百并发用户，可作为公开网站后端上线。
  * **时序记忆系统**：时序边 + 快照机制，支持时间旅行查询，查询性能提升 20-200 倍。
  * **智能影响分析**：依赖矩阵优化算法，影响分析性能提升 100 倍（100 场景规模）。
  * **云端实体消解**：Gemini Flash API，成本降低 67%，速度提升 1.5 倍，无需本地 GPU。
  * **完整版本控制**：Git 式分支管理，支持多分支并行创作、对比、合并、回滚。

### **8.2 系统能力指标**

  * **功能完整性**: 从 28% 提升至 100%（补全动态状态追踪、一致性检查、多米诺重构、时序查询、懒惰计算）
  * **并发能力**: 从单连接提升至 100+ 并发用户
  * **查询性能**: 读操作 P99 < 100ms，写操作 P99 < 200ms
  * **吞吐量**: > 100 QPS（混合读写）
  * **测试覆盖率**: 单元测试 > 85%，集成测试 > 80%，E2E 测试 > 70%

### **8.3 实施路径**

本系统采用**彻底重构策略**，删除旧 Kùzu 代码（1200 行），新增 Memgraph 实现（4150 行），预计 11 周完整交付。关键成功因素包括：

1. **性能 POC 先行**：Week 1 必须完成 Memgraph 性能验证
2. **严格 TDD**：每个功能先写测试，保证质量
3. **增量交付**：每周交付可验证的里程碑
4. **回滚保障**：提供完整的数据迁移和回滚方案

-----

## **附录 A：图数据库重构方案对照**

本设计文档与 `doc/graph_refactor_final_plan.md` 的对应关系：

| 设计文档章节 | 重构方案章节 | 核心内容 |
|------------|------------|---------|
| 2.1 技术栈选型 | 1.4 技术栈决策 | Memgraph + GQLAlchemy 选型理由 |
| 3.0 图数据库重构说明 | 一、执行摘要 | 重构目标、核心问题、收益分析 |
| 3.2 通用实体与状态模型 | 二、架构设计要点 | 时序边、WorldSnapshot 设计 |
| 3.3 数据库映射策略 | 2.1 双子图架构 | 结构子图 + 叙事子图 |
| 4.2 场景上下文加载 | 3.1 快照+增量混合架构 | 查询优化（O(1) 快照命中）|
| 4.4 状态提取与人工确认 | 3.3 实体消解的云端方案 | Gemini Flash API 集成 |
| 5.1 局部修复 | 3.2 影响分析的依赖矩阵优化 | 依赖矩阵算法（O(E) 查询）|
| 5.2 脏标记机制 | 3.5 多米诺重构算法 | 影响分析 + 局部修复 |
| 5.3 Git 式分支管理 | 2.2 核心节点设计要点 | Branch/BranchHead/Commit |
| 7.1 核心数据结构 | 3.4 时序边失效机制 | 时序边更新逻辑 |
| 7.3 落地路线图 | 五、实施计划 | 11 周分阶段交付计划 |

**详细实施计划**：请参考 `doc/graph_refactor_final_plan.md` 第五章，包含：
- Phase 1 (Week 1-2): 环境搭建 + 旧代码清理
- Phase 2 (Week 3-5): 双子图架构 + 时序边
- Phase 3 (Week 6-7): 实体消解 + 影响分析
- Phase 4 (Week 8-9): 数据迁移 + API 适配
- Phase 5 (Week 10-11): 性能优化 + 文档

**测试规范**：请参考 `doc/graph_refactor_final_plan.md` 第四章，包含：
- 单元测试覆盖率 > 85%
- 集成测试覆盖率 > 80%
- E2E 测试覆盖率 > 70%
- 核心测试用例（时序边、实体消解、影响分析）

**性能指标**：请参考 `doc/graph_refactor_final_plan.md` 第七章，包含：
- 读操作延迟 P99 < 100ms
- 写操作延迟 P99 < 200ms
- 吞吐量 > 100 QPS
- 并发用户数 > 100

-----

**文档维护说明**：
- 本设计文档关注系统架构和创作工作流
- 重构方案文档关注技术实现和工程细节
- 两份文档需保持同步更新
